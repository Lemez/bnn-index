<div id='info'>
	<div class='blurb'>
		<div id='mobilenav'>
			<h3>What?</h3>
		<p>This project analyses Britain's main newspapers to see their effect on our daily collective mood.<sup>*</sup> </p>
		
	</div>
		<h3>Why?</h3>
		<p>"It's good to stay informed" is a platitude I grew up on. I turn to online news several times a day to kill spare moments. But what does this do to my mood? Apart from the story itself, what other information am I getting? This project is a humble attempt to find out.</p>
		<h3>How?</h3>
		<p>
			Once every hour, we take the RSS feed from Britain's 'top' newspapers<sup style='font-size:20px;'>*</sup>, and run the first ten headlines through sentiment analysis to see how they score. Stories are assessed for 'positivity' or 'negativity', according to two manually-created sentiment analysis dictionaries (see below).</p>

		<p><em><sup>*</sup>In his infinite wisdom, no Murdoch papers are available any more as RSS feeds. I may or may not get round to scraping them in other ways.</em></p>

		<h3>Steps</h3>
		<p>Each headline goes through a bunch of steps: I'll take a slightly adapted-for-demo-purposes recent headline from the Daily Express on 6th Sep 2015 as an example:</p>
	<span class='info-ex'><em>SHAME! Trump: hero suffering 'post-traumatic stress' from UN's conflict REFUSED $100 credit</em></span></br></br>
		<ol>
			<!-- title.sentence_to_pos -->
			<li>Split sentence into a tokens, <span class='info-ex'><em>SHAME, !, Trump, :, hero, suffering, ', post-traumatic, stress, ', from, UN, 's, conflict, REFUSED, $100, credit</em></span></li>
			
			<li>Get part of speech for each token,  <span class='info-ex'><em>SHAME/noun, !/punctuation, Trump/noun, etc</em></span> </li>

			 <!-- title.reject{|a| a[0].to_i!=0 || a[1][0]=="P"} -->
			<li>Remove punctuation tokens and numbers,  <span class='info-ex'><em>SHAME, Trump, hero, suffering, post-traumatic, stress, from, UN, conflict, REFUSED, credit</em></span></li>

			<li>Split words with internal apostrophe into separate words,  <span class='info-ex'><em>SHAME, Trump, hero, suffering, post, traumatic, stress, from, UN, 's, conflict, REFUSED, credit</em></span></li>
			
			<li>Remove acronyms, non-dictionary words and personalities with names that are like words,  <span class='info-ex'><em>SHAME, hero, suffering, post, traumatic, stress, from, conflict, REFUSED, credit</em></span></li>

			<li>Make a note of upper-case dictionary words,  <span class='info-ex'><em> <span class='info-ex shout'>SHAME</span>, hero, suffering, post, traumatic, stress, conflict, <span class='info-ex shout'>REFUSED</span>, credit</em></span></li></li>

			<li>Make all words lower-case,  <span class='info-ex'><em>shame, hero, suffering, post, traumatic, stress, conflict, refused, credit</em></span> </li>

			<li>Get the lemma of each token,  <span class='info-ex'><em>shame, hero, suffer, post, traumatic, stress, conflict, refuse, credit</em></span> </li>
				
		</ol>

		<h3>Scoring</h3>
			<p> Each word gets looked up in the dictionaries and given a sentiment score, that ranges between +3 (eg. 'wonderful') and -3 (eg. 'terrifying'), then we average the scores for each word over the two dictionaries, and add them up to give a final score for the headline as a whole. <a href="https://newrepublic.com/article/117390/netiquette-capitalization-how-caps-became-code-yelling" ><span class="shout">SHOUTING</span></a> is part of negative semantics, and so each dictionary shouting word scores an extra -1 point.</p>

		<p>An example using our headline above:</p>
		<div class='info_example'>  

				<span class='info-ex tabbed'>WORD</span><span class='info-ex tabbed'>Overall</span><span class='info-ex tabbed'>Afinn,MPQA</span><span class='info-ex tabbed'>SHOUT?</span><br>
				<span class='info-ex shout tabbed'>shame</span>
			<span class='info-ex tabbed celltotal'> -2.75</span>
			<span class='info-ex tabbed'>-2.0,-1.5</span>
			<span class='info-ex tabbed'>Y</span><br>
				<span class='info-ex tabbed'>hero</span>
				<span class='info-ex tabbed celltotal'> 2.5</span>
				<span class='info-ex tabbed'> 2.0,3.0</span><br>
				<span class='info-ex tabbed'>suffer</span>
				<span class='info-ex tabbed celltotal'> -1.25</span>
				<span class='info-ex tabbed'>-2.0,-0.5</span><br>
			<span class='info-ex tabbed'>post</span>
			<span class='info-ex tabbed celltotal'> 0 </span>
			<span class='info-ex tabbed'> 0, 0</span><br>
			<span class='info-ex tabbed'>traumatic</span>
			<span class='info-ex tabbed celltotal'> -1.5 </span>
			<span class='info-ex tabbed'> -3.0,0</span><br>
			<span class='info-ex tabbed'>stress</span>
			<span class='info-ex tabbed celltotal'> -0.75</span>
			<span class='info-ex tabbed'> 0,-1.5</span><br>
			<span class='info-ex tabbed'>conflict</span>
			<span class='info-ex tabbed celltotal'> -1.5</span>
			<span class='info-ex tabbed'> -2.0,-1.0</span><br>
			<span class='info-ex shout tabbed'> refuse</span>
			<span class='info-ex tabbed celltotal'> -2.75 </span>
			<span class='info-ex tabbed'> -2.0,-1.5</span>
			<span class='info-ex tabbed'>Y</span><br>
			<span class='info-ex tabbed'>credit</span>
			<span class='info-ex tabbed celltotal'>0</span>
			<span class='info-ex tabbed'>0, 0</span> </div><br>
			<span class='info-ex tabbed'>TOTAL</span>
			
			<span class='info-ex tabbed celltotal'>-8</span> </div>
			<span class='info-ex tabbed'></span><br>

		<h3>Testing and Analysis</h3>
			<p>Three different tools were tested, and manually assessed to check efficacy (click for more info): </p>
			<ol class='analysers'>
				<li><a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010" target="_blank">AFINN-111</a></li>
			<li><a href="http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/" target="_blank">MPQA Subjectivity Lexicon</a></li>
			<li><a href="https://github.com/malavbhavsar/sentimentalizer" target="_blank">Naive Bayes Classifier (Sentimentalizer)</a> </li>
		</ol>

			<p>In the first test, sixty headlines were checked against the three tools. Ultimately, sentiment analysis is a rather subjective exercise, so I went down the list of scores and picked out the stories <em>I </em> thought were particularly offensive, and compared the scores. The full csv of initial data for comparison is <a href="https://www.dropbox.com/s/tngc6yqcff9ylve/rss2mixed.csv?dl=1">here</a> (key: Wiebe-MPQA, Sent-Naive Classifier). Taken alone, Wiebe and AFINN got the score badly wrong (ie weren't offended by something I found grossly offensive, or were offended by something harmless) around 20% of the time, but averaged together, the rate dropped dramatically in the test data. </p>
		<h3>Codebase</h3>
		<div class='codechart'></div>
	
		<script type="text/javascript">
	    var dataArray = <%=@project%>;
	    var total = <%=@total%>;
	    // var langsArray = <%=@languages%>;

	    var w = $(window).width(),
    	barHeight = 20;

		  x = d3.scale.linear()
		  .domain([0, 100])
		  .range([0, w]);

		d3.select(".codechart")
		  .selectAll("div")
		    .data(dataArray)
		  .enter().append("div")
		    .style("width", function(d) { return x(d.amount) + "px"; })
		    .text(function(d) { return d.lang; });

		var chart = d3.select(".bar-chart-svg")
		    .attr("width", w)
		    .attr("height", barHeight);

		var bar = chart.selectAll("g")
		    .data(dataArray)
		  .enter().append("g")
		    .attr("transform", function(d, i) { return "translate(" + "0" + "," + i * barHeight + ")"; });

		bar.append("rect")
		    .attr("width", x)
		    .attr("height", barHeight - 1);

		bar.append("text")
		    .attr("x", function(d) { return x(d) - 3; })
		    .attr("y", barHeight / 2)
		    .attr("dy", ".35em")
		    .text(function(d) { return d.amount; });

		</script>
		<br/>
		<h3>Can I improve it?</h3>
		<p>Sure you can, there's lots more to do, top of the list being N-grams. And the second one being showing some love to Murdoch (see above).</p><p> Please fork it over on <a href="https://github.com/Lemez/serenity-padrino" target="_blank">Github</a> .</p>
		<p>If you have any thoughts, comments, improvements, go to the  <a href="https://github.com/Lemez/serenity-padrino" target="_blank">Hacker News thread</a> .</p>

		
	</div>
</div>