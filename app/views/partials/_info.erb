<div id='info'>
	<div class='blurb'>
		<div id='mobilenav'>
			<h3>What?</h3>
		<p>This project analyses Britain's main newspapers to see their effect on our health.<sup>*</sup> </p>
		
	</div>
		<h3>Why?</h3>
		<p>"It's good to stay informed" is a platitude I grew up on. I turn to online news several times a day to kill spare moments. But what does this do to my mood? Apart from the story itself, what other information am I getting? This project is a humble attempt to find out.</p>
		<h3>How?</h3>
		<p>
			Once every hour, we take the RSS feed from Britain's 'top' newspapers, and run the first ten headlines through sentiment analysis to see how they score. Stories are assessed for 'positivity' or 'negativity', according to two manually-created sentiment analysis dictionaries (see below).</p>
			<p> Each word gets looked up in the dictionaries and given a sentiment score, that ranges between +3 (eg. 'wonderful') and -3 (eg. 'terrifying'), then we add the scores for each word to give a final score for the headline as a whole.</p>


		<h3>Steps</h3>
		<p>Each headline goes through a bunch of steps: I'll take a slightly adapted-for-demo-purposes recent headline from the Daily Express on 6th Sep 2015 as an example:</p>
	<span class='info-ex'><em>SHAME! Trump: hero suffering 'post-traumatic stress' from UN's conflict REFUSED $100 credit</em></span></br></br>
		<ol>
			<!-- title.sentence_to_pos -->
			<li>Split sentence into a tokens, <span class='info-ex'><em>SHAME, !, Trump, :, hero, suffering, ', post-traumatic, stress, ', from, UN, 's, conflict, REFUSED, $100, credit</em></span></li>
			
			<li>Get part of speech for each token,  <span class='info-ex'><em>SHAME/noun, !/punctuation, Trump/noun, etc</em></span> </li>

			 <!-- title.reject{|a| a[0].to_i!=0 || a[1][0]=="P"} -->
			<li>Remove punctuation tokens and numbers,  <span class='info-ex'><em>SHAME, Trump, hero, suffering, post-traumatic, stress, from, UN, conflict, REFUSED, credit</em></span></li>

			<li>Split words with internal apostrophe into separate words,  <span class='info-ex'><em>SHAME, Trump, hero, suffering, post, traumatic, stress, from, UN, 's, conflict, REFUSED, credit</em></span></li>
			
			<li>Remove acronyms, non-dictionary words and personalities with names that are like words,  <span class='info-ex'><em>SHAME, hero, suffering, post, traumatic, stress, from, conflict, REFUSED, credit</em></span></li>

			<li>Make a note of upper-case dictionary words,  <span class='info-ex'><em> <span class='info-ex shout'>SHAME</span>, hero, suffering, post, traumatic, stress, conflict, <span class='info-ex shout'>REFUSED</span>, credit</em></span></li></li>

			<li>Make all words lower-case,  <span class='info-ex'><em>shame, hero, suffering, post, traumatic, stress, conflict, refused, credit</em></span> </li>

			<li>Get the lemma of each token,  <span class='info-ex'><em>suffer, refuse</em></span> </li>
			

			

			

			
			
			
		</ol>

		<h3>Testing and Analysis</h3>
		<p>Three different tools were tested, and manually assessed to check efficacy (click for more info): </p>
		<ol class='analysers'>
			<li><a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010" target="_blank">AFINN-111</a></li>
		<li><a href="http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/" target="_blank">MPQA Subjectivity Lexicon</a></li>
		<li><a href="https://github.com/malavbhavsar/sentimentalizer" target="_blank">Naive Bayes Classifier (Sentimentalizer)</a> </li>
	</ol>

		<p>In the first test, sixty headlines were checked against the three tools. Ultimately, sentiment analysis is a rather subjective exercise, so I went down the list of scores and picked out the stories <em>I </em> thought were particularly offensive, and compared the scores. The full csv of initial data for comparison is <a href="https://www.dropbox.com/s/tngc6yqcff9ylve/rss2mixed.csv?dl=1">here</a> (key: Wiebe-MPQA, Sent-Naive Classifier). Taken alone, Wiebe and AFINN got the score badly wrong (ie weren't offended by something I found grossly offensive, or were offended by something harmless) around 20% of the time, but averaged together, the rate dropped dramatically in the test data. </p>

		<h3>What is it coded in?</h3>
		<div class='codechart'></div>
	
		<script type="text/javascript">
	    var dataArray = <%=@project%>;
	    var total = <%=@total%>;
	    // var langsArray = <%=@languages%>;

	    var w = $(window).width(),
    	barHeight = 20;

		  x = d3.scale.linear()
		  .domain([0, 100])
		  .range([0, w]);

		d3.select(".codechart")
		  .selectAll("div")
		    .data(dataArray)
		  .enter().append("div")
		    .style("width", function(d) { return x(d.amount) + "px"; })
		    .text(function(d) { return d.lang; });

		var chart = d3.select(".bar-chart-svg")
		    .attr("width", w)
		    .attr("height", barHeight);

		var bar = chart.selectAll("g")
		    .data(dataArray)
		  .enter().append("g")
		    .attr("transform", function(d, i) { return "translate(" + "0" + "," + i * barHeight + ")"; });

		bar.append("rect")
		    .attr("width", x)
		    .attr("height", barHeight - 1);

		bar.append("text")
		    .attr("x", function(d) { return x(d) - 3; })
		    .attr("y", barHeight / 2)
		    .attr("dy", ".35em")
		    .text(function(d) { return d.amount; });

		</script>
		<br/>
		<h3>Can I improve it?</h3>
		<p>Sure you can, please fork it over on <a href="https://github.com/Lemez/serenity-padrino" target="_blank">Github</a> .</p>
		<p>If you have any thoughts, comments, improvements, go to the  <a href="https://github.com/Lemez/serenity-padrino" target="_blank">Hacker News thread</a> .</p>
	</div>
</div>